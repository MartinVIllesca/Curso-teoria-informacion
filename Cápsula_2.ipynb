{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cápsula_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NoYP-r5pNiWe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinVIllesca/Curso-teoria-informacion/blob/master/C%C3%A1psula_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEjyqy2rtvcr",
        "colab_type": "text"
      },
      "source": [
        "# Cápsula #2: *Representation Learning*\n",
        "\n",
        "### EL7024 - Teoría de la Información: Fundamentos y Aplicaciones \n",
        "### Information and Decision Systems Group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATN5Ljpqtw8B",
        "colab_type": "text"
      },
      "source": [
        "En esta cápsula se revisarán los fundamentos y ejemplos experimentales de [*Autoencoders* Variacionales](https://arxiv.org/abs/1312.6114) (Kingma & Welling, 2014) y del [Método del *Information Bottleneck*](https://arxiv.org/abs/physics/0004057) (Tishby et al., 1999)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy0FYCaYt32I",
        "colab_type": "text"
      },
      "source": [
        "## Preliminares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs-M3TggtdCX",
        "colab_type": "code",
        "outputId": "3d01a9fb-c851-4a4f-9c94-80a4a9b443ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "%load_ext tensorboard\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.distributions as D\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from copy import deepcopy\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits import mplot3d\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.decomposition import PCA\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikz5qEoXt9tJ",
        "colab_type": "code",
        "outputId": "353a4fe0-d911-4495-aadf-d41b0a75a9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  2 05:39:20 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    12W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c3jh_bjuDAx",
        "colab_type": "text"
      },
      "source": [
        "### MNIST *Dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA_qM3g8uJFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Batch Sizes\n",
        "train_batch_size = 100\n",
        "val_batch_size = 1000\n",
        "\n",
        "# Train-Val Split\n",
        "train_dataset_mnist = datasets.MNIST(root='./', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()]))\n",
        "\n",
        "val_dataset_mnist = datasets.MNIST(root='./', train=False, \n",
        "                        transform=transforms.Compose([\n",
        "                        transforms.ToTensor()]))\n",
        "\n",
        "# DataLoaders\n",
        "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist,\n",
        "                                           batch_size = train_batch_size)\n",
        "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist,\n",
        "                                          batch_size = val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI94Rxm7uLrY",
        "colab_type": "code",
        "outputId": "6420f499-9db5-4fee-e83c-f38ebb9771f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "index = np.random.randint(len(val_loader_mnist.dataset))\n",
        "img = val_loader_mnist.dataset[index][0].numpy()[0]\n",
        "print('Label : {}'.format(val_loader_mnist.dataset[index][1]))\n",
        "plt.figure()\n",
        "plt.imshow(img,cmap=cm.gray)\n",
        "plt.show()\n",
        "print('Max  value: {}, Min value: {}'.format(np.amax(img), np.amin(img)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label : 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max  value: 1.0, Min value: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cFceFekuSXo",
        "colab_type": "text"
      },
      "source": [
        "## 1.- Inferencia Variacional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDEXkpM8uTiY",
        "colab_type": "text"
      },
      "source": [
        "Es un método para aproximar distribuciones de probabilidad difíciles de tratar, especialmente cuando solo se tienen muestras de la distribución. Esto se hace por medio de optimización sobre una familia de distribuciones candidatas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz_-q9I3uYcu",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.- Motivación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha1_33GKubGg",
        "colab_type": "text"
      },
      "source": [
        "Desde una perspectiva Bayesiana, considérense las variables aleatorias $\\mathbf{X} \\in \\mathcal{X}$ y $\\mathbf{Z} \\in \\mathcal{Z}$, cuya distribución conjunta está dada por:\n",
        "\n",
        "\\begin{equation}\n",
        "p(\\mathbf{x}, \\mathbf{z}) = p(\\mathbf{x}|\\mathbf{z})p(\\mathbf{z}),\n",
        "\\end{equation}\n",
        "\n",
        "donde $p(\\mathbf{z})$ se percibe como un *prior* sobre la distribución de la variable **latente**, relacionada estadísticamente con las **observaciones** por medio de la verosimilitud $p(\\mathbf{x}|\\mathbf{z})$.\n",
        "\n",
        "Un modelo de inferencia/estimación Bayesiano apunta a obtener la distribución de $\\mathbf{Z}$ condicionada a las observaciones, es decir la *posterior* $p(\\mathbf{z}|\\mathbf{x})$.\n",
        "\n",
        "El cálculo de cada una de estas distribuciones a partir de datos suele ser complicado, por lo que típicamente se recurre a mecanísmos de aproximación entre ellos la **Inferencia Variacional**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aljsOCJxupP9",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.- Planteamiento del Problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1hxhJD-urOn",
        "colab_type": "text"
      },
      "source": [
        "Para el caso (más usual) de estimar la *posterior* $p(\\mathbf{z}|\\mathbf{x})$ a partir de datos o muestras de la variable $\\mathbf{x}$ se recurre a escribir:\n",
        "\n",
        "\\begin{equation}\n",
        "p(\\mathbf{z}|\\mathbf{x}) = \\frac{p(\\mathbf{x},\\mathbf{z})}{p(\\mathbf{x})}, \\hspace{5mm} p(\\mathbf{x}) = \\int_{\\mathcal{Z}}p(\\mathbf{x},\\mathbf{z})d\\mathbf{z}\n",
        "\\end{equation}\n",
        "\n",
        "No obstante, dadas las dificultades del cálculo directo de esta distribución se plantea su resolución (aproximada) como un problema de optimización sobre un nuevo conjunto de **parámetros**. En este sentido, se busca una distribución $q^{*}(\\mathbf{z})$ parametrizada por $\\theta \\in \\Theta$ tal que:\n",
        "\n",
        "\\begin{equation}\n",
        "q^{*}(\\mathbf{z}) \\approx p(\\mathbf{z}|\\mathbf{x})\n",
        "\\end{equation}\n",
        "\n",
        "Esto quiere decir que $\\theta$ induce una familia de distribuciones paramétricas sobre $\\mathbf{Z}$, denominada $\\mathcal{Q}$.\n",
        "\n",
        "Resta definir el funcional sobre el cual se realiza el proceso de optimización. Naturalmente, aparece en este punto el concepto de **divergencia**; por lo que típicamente el problema se plantea finalmente como:\n",
        "\n",
        "\\begin{equation}\n",
        "q^{*}(\\mathbf{z}) = \\underset{q(\\mathbf{z}) \\in \\mathcal{Q}}{\\operatorname{arg min}} KL(q(\\mathbf{z})||p(\\mathbf{z}|\\mathbf{x})) \\tag{1}\n",
        "\\end{equation}\n",
        "\n",
        "En particular, resulta más práctico caracterizar a su vez la familia de distribuciones $\\mathcal{Q}$ por medio de un espacio paramétrico $\\Theta$, con lo cual se formula el problema como:\n",
        "\n",
        "\\begin{equation}\n",
        "q_{\\theta^{*}}(\\mathbf{z}) = \\underset{q_{\\theta}(\\mathbf{z}),\\hspace{1mm} \\theta \\in \\Theta}{\\operatorname{arg min}} KL(q_{\\theta}(\\mathbf{z})||p(\\mathbf{z}|\\mathbf{x})) \\tag{2}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LP67EUw3eBZ",
        "colab_type": "text"
      },
      "source": [
        "### 1.3.- La *Evidence Lower Bound* (ELBO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LppBcHrt3ee-",
        "colab_type": "text"
      },
      "source": [
        "Lamentablemente, aún planteado de esta forma el problema requiere calcular la **evidencia** $p(\\mathbf{x})$, por lo que se define un funcional \"equivalente\" a la divergencia de Kullback-Leibler, denominado *Evidence Lower Bound* o ELBO:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "ELBO(q) &= \\mathbb{E}_{\\mathbf{Z} \\sim q(\\mathbf{z})}\\{\\log{p(\\mathbf{x},\\mathbf{z})}\\} - \\mathbb{E}_{\\mathbf{Z} \\sim q(\\mathbf{z})}\\{\\log{q(\\mathbf{z})}\\} \\\\\n",
        "&= \\mathbb{E}_{\\mathbf{Z} \\sim q(\\mathbf{z})}\\{\\log{p(\\mathbf{x}|\\mathbf{z})}\\} - KL(q(\\mathbf{z})||p(\\mathbf{z}))\n",
        "\\end{split} \\tag{3}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3ifzcDOCdxy",
        "colab_type": "text"
      },
      "source": [
        "### 1.4.- Síntesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17lJHWxWCdHE",
        "colab_type": "text"
      },
      "source": [
        "Lo importante del planteamiento detrás de **Inferencia Variacional** es que permite calcular (en forma aproximada) una distribución de interés sobre una variable aleatoria por medio de la optimización sobre los parámetros $\\theta \\in \\Theta$, introduciendo así una densidad \"auxiliar\" $q_{\\theta}(\\cdot)$ sobre dicha variable aleatoria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXsIPCgBCtVv",
        "colab_type": "text"
      },
      "source": [
        "## 2.- *Autoencoders* Variacionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJHqffa_Ct75",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.- *Autoencoders*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrmclbEsCwlS",
        "colab_type": "text"
      },
      "source": [
        "Los Autoencoders son una subcategoría de las redes neuronales, orientadas a problemas y/o etapas no supervisadas de aprendizaje. El objetivo es que la red aprenda a generar Representaciones Latentes de un fenómeno $X$ a partir de los datos de entrada $\\{x_{i}\\}_{i=1}^{N}$, y reconstruir estos últimos a partir del código latente.\n",
        "\n",
        "Entre las utilidades que presentan los autoencoders se encuentran:\n",
        "\n",
        "*   Reducción de Dimensionalidad\n",
        "*   Representación Eficiente de Datos\n",
        "*   Obtención de Características y *Pretraining* de Redes\n",
        "*   *Denoising*\n",
        "*   Modelos Generativos\n",
        "\n",
        "Estructuralmente los autoencoders se componen de $2$ partes:\n",
        "\n",
        "*   *Encoder*: Transforma las entradas al Espacio Latente. A veces se le denomina *Recognition Model*.\n",
        "*   *Decoder*: Realiza el proceso inverso al *encoder*. Representa la parte Generativa del modelo.\n",
        "\n",
        "      ![texto alternativo](https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Autoencoder_structure.png/350px-Autoencoder_structure.png)\n",
        "\n",
        "Este tipo de modelo se entrena por medio de alguna Función de Pérdida, denominada *Reconstruction Loss*. Cuando se incorporan términos de regularización sobre el Espacio Latente se suele denominarlos por *Latent Loss*.\n",
        "\n",
        "Más concretamente, denotando el *encoder* por la función $\\Phi$ y el *decoder* por la función $\\Psi$ se tiene que:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    &\\Phi: \\mathcal{X} \\to \\mathcal{Z} \\\\\n",
        "    &\\Psi: \\mathcal{Z} \\to \\mathcal{X},\n",
        "  \\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "con lo cual, la salida de la red corresponde a una **reconstrucción** de la entrada $\\mathbf{x}$, $\\mathbf{x}'$:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\mathbf{x}' = \\Psi(\\mathbf{z}) =  \\Psi\\circ\\Phi(\\mathbf{x})\n",
        "\\end{equation}\n",
        "\n",
        "Típicamente, se utiliza como *Reconstruction Loss* el error cuadrático entre $\\mathbf{x}$ y $\\mathbf{x}'$, por lo que el modelo completo del autoencoder se define como:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\Phi, \\Psi = \\underset{\\Phi, \\Psi}{\\operatorname{arg min}}||\\mathbf{x} - \\Psi\\circ\\Phi(\\mathbf{x})||^{2}\n",
        "\\end{equation}\n",
        "\n",
        "Un *autoencoder* variacional sigue el mismo principio expuesto anteriormente, con la diferencia de que se desea que tanto el *encoder* como el *decoder* sean probabilísticos, en el sentido de que cada uno induce un mapeo estocástico desde el espacio de entradas al espacio latente, y viceversa, permitiendo hacer inferencia en forma eficiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VGUPSG9DMZR",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.- *Autoencoders* Variacionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpu3FXHODTAf",
        "colab_type": "text"
      },
      "source": [
        "Volviendo al punto anterior, es evidente que un *autoencoder* tradicional es entrenado para capturar en su *encoder* una aproximación degenerada de $p(\\mathbf{z}|\\mathbf{x})$ en el sentido que, dada una muestra $\\mathcal{x}_{i}$:\n",
        "\n",
        "\\begin{equation}\n",
        "P(\\mathbf{Z} = \\Phi(\\mathcal{x}_{i})|\\mathbf{X} = \\mathcal{x}_{i}) = 1\n",
        "\\end{equation}\n",
        "\n",
        "Es decir, no es posible hacer inferencia desde una perspectiva estadística. En este sentido, no es posible realizar una caracterización del siguiente **modelo gráfico dirigido** (el cual es justamente el estudiado en la sección de Inferencia Variacional):\n",
        "\n",
        ">>>>>>>>![texto alternativo](https://jaan.io/images/graphical-model-variational-autoencoder.png)\n",
        "\n",
        "\n",
        "En base a un argumento similar, un *autoencoder* tradicional posee en su etapa de *decoder* un modelo generativo considerablemente pobre al ser determinístico, condicionado exclusivamente a la entrada $\\mathbf{x}$.\n",
        "\n",
        "\\\\\n",
        "\n",
        "La pregunta clave es entonces: ¿cómo podemos hacer inferencia sobre $p(\\mathbf{z}|\\mathbf{x})$ y obtener con ello un modelo generativo más expresivo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwdoIjKIDlkg",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.1.- Fundamentos Teóricos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biGOxRzSDon5",
        "colab_type": "text"
      },
      "source": [
        "##### Planteamiento del Problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Btw8EnuDp_w",
        "colab_type": "text"
      },
      "source": [
        "Consideremos el dataset $\\mathcal{X} = \\left\\{\\mathbf{x}^{(i)}\\right\\}_{i=1}^{N}$, formado por muestras *i.i.d.* del vector aleatorio $K$-dimensional $\\mathbf{X}$. Tal como revisamos en la sección de Inferencia Variacional, se asume que el proceso generativo de $\\mathbf{X}$ se rige según la variable (aleatoria) latente $J$-dimensional $\\mathbf{Z}$ y es parametrizado por $\\theta^{*}$:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\mathbf{X}  \\sim p_{\\theta^{*}}(\\mathbf{x}|\\mathbf{z}), \\hspace{5mm} \\mathbf{Z} \\sim p_{\\theta^{*}}(\\mathbf{z}),\n",
        "\\end{equation}\n",
        "\n",
        "donde $p_{\\theta^{*}}(\\mathbf{z})$ consiste en **alguna** distribución *a priori*.\n",
        "\n",
        "En términos prácticos, tanto los valores $\\mathbf{z}$ como $\\theta^{*}$ son desconocidos\n",
        "\n",
        "> **Nota**: $\\mathbf{Z}$ gobierna el comportamiento estadístico de $\\mathbf{X}$ (dado que es una **variable latente**), mientras que $\\theta^{*}$ determina la forma en que esto ocurre, es decir determina el efecto de $\\mathbf{z}$ sobre $\\mathbf{x}$ por medio de $p_{\\theta^{*}}(\\mathbf{x}|\\mathbf{z})$.\n",
        "\n",
        "Por lo tanto, en un problema de inferencia \"clásico\" se apunta a determinar el valor de $\\mathbf{z}$ para distintos puntos en el dominio de $\\mathbf{X}$, para lo cual se debe a su vez tener un valor (aproximado) de los parámetros $\\theta^{*}$.\n",
        "\n",
        "Asumiendo que $p_{\\theta^{*}}(\\mathbf{x}|\\mathbf{z})$ y $p_{\\theta^{*}}(\\mathbf{z})$ viven en una familia de distribuciones paramétricas $\\mathcal{Q}$ determinada por $\\theta \\in \\Theta$, es posible emplear Inferencia Variacional para aproximarlas.\n",
        "\n",
        "Para abordar el problema se introduce un ***Recognition Model*** (o ***Encoder* probabilístico**) $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$, el cual es una aproximación de la distribución posterior $p_{\\theta^{*}}(\\mathbf{z}|\\mathbf{x})$. Los parámetros $\\phi$ son aprendidos simultáneamente con los del **Modelo Generativo** (denominado ***Decoder* probabilístico**) $p_{\\theta}(\\mathbf{x}|\\mathbf{z})$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHDiOoohExeV",
        "colab_type": "text"
      },
      "source": [
        "##### Tratamiento del Problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOV8UnmqEyBo",
        "colab_type": "text"
      },
      "source": [
        "El objetivo se plantea en forma similar a como se propone en Inferencia Variacional. En este caso se propone minimizar la divergencia entre $q_{\\phi}(\\mathbf{z}|\\color{red}{\\mathbf{x}})$ y $p_{\\theta^{*}}(\\mathbf{z}|\\mathbf{x})$. De esta forma, se rescata una cota inferior para la Evidencia, tal como en Inferencia Variacional:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\log p_{\\theta^{*}}(\\mathbf{x}) \\geq \\mathbb{E}_{\\mathbf{Z} \\sim q_{\\phi}(\\mathbf{z}|\\mathbf{x})}\\left\\{\\log p_{\\theta^{*}}(\\mathbf{x}|\\mathbf{z})\\right\\} - KL\\left(q_{\\phi}(\\mathbf{z}|\\mathbf{x})||p_{\\theta^{*}}(\\mathbf{z})\\right)\n",
        "\\end{equation}\n",
        "\n",
        "No obstante, tanto $p_{\\theta^{*}}(\\mathbf{x}|\\mathbf{z})$ como $p_{\\theta^{*}}(\\mathbf{z})$ son desconocidos. Si bien siguiendo el enfoque Bayesiano de Inferencia Variacional en este punto se emplea un *prior* $p_{\\theta}(\\mathbf{z})$ (más precisamente $p(\\mathbf{z})$) aún es insuficiente para abordar este objetivo. La razón de esto es que no se asume conocimiento preciso sobre el Modelo Generativo $p_{\\theta^{*}}(\\mathbf{x}|\\mathbf{z})$, sino que se busca aproximarlo por medio de $p_{\\theta}(\\mathbf{x}|\\mathbf{z}) \\approx p_{\\theta^{*}}(\\mathbf{x}|\\mathbf{z})$.\n",
        "\n",
        "Reemplazando, el funcional a optimizar por cada muestra $\\mathbf{x}^{(i)}$ está dado por\n",
        "\n",
        "\\begin{equation}\n",
        "  \\mathcal{L}(\\phi, \\theta, \\mathbf{x}^{(i)}) = \\mathbb{E}_{\\mathbf{Z} \\sim q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})}\\left\\{\\log p_{\\theta}(\\mathbf{x}^{(i)}|\\mathbf{z})\\right\\} - KL\\left(q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})||p_{\\theta}(\\mathbf{z})\\right) \\tag{4}\n",
        "\\end{equation}\n",
        "\n",
        "> **Nota**: El supuesto de que $p_{\\theta}(\\mathbf{x}|\\mathbf{z}) \\approx p_{\\theta^{*}}(\\mathbf{x}|\\mathbf{z})$ es bastante fuerte puesto que nada más allá del propio proceso de optimización ofrece alguna garantía de que esto sea así efectivamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy0LZMdwNZMT",
        "colab_type": "text"
      },
      "source": [
        "Usualmente, al tratarse de esperanzas, estos términos son difíciles de tratar en forma eficiente, más aún si no se tiene acceso en forma directa a $p_{\\theta}(\\mathbf{x^{(i)}}|z)$ ni a $q_{\\phi}(\\mathbf{z}|\\mathbf{x^{(i)}})$ ni tampoco a muestras de $\\mathbf{Z}$ que permitan alguna estimación empírica de las esperanzas.\n",
        "\n",
        "No obstante, bajo supuestos sobre la \"forma\" de estas distribuciones es posible:\n",
        "\n",
        "* Calcular en forma cerrada la verosimilitud de $\\mathbf{x^{(i)}}$.\n",
        "* Muestrear la variable latente (en forma condicional a $\\mathbf{x^{(i)}}$) gracias al  ***Reparametrization Trick***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqhp8mJgNZ1u",
        "colab_type": "text"
      },
      "source": [
        "##### *Reparametrization Trick*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1RhHG37NcBO",
        "colab_type": "text"
      },
      "source": [
        "El *Reparametrization Trick* cosiste en reparametrizar la variable aleatoria latente $\\mathbf{Z}$ como una función determinística de dos variables aleatorias: la variable $\\mathbf{X}$ y un ruido aleatorio $\\epsilon$ con recorrido en $\\xi$. Esta función $g_{\\phi}(\\mathbf{x},\\epsilon)$ es diferenciable respecto a los parámetros $\\phi$ del *encoder*, con lo cual es posible tanto muestrear (a partir de muestrear $\\mathbf{X}$ y $\\epsilon$) y propagar los gradientes a través de la red para actualizar dichos parámetros. Formalmente, la función $g_{\\phi}(\\mathbf{x},\\epsilon)$ es tal que:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    g_{\\phi} : &\\mathcal{X} \\times \\xi \\to \\mathcal{Z}\\\\\n",
        "               &\\mathbf{x}, \\epsilon \\to \\mathbf{z} = g_{\\phi}(\\mathbf{x},\\epsilon), \\hspace{5mm} \\epsilon \\sim p(\\epsilon)\n",
        "  \\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "y se satisface en consecuencia que $\\mathbf{z} = g_{\\phi}(\\mathbf{x},\\epsilon) \\sim q_{\\phi}(\\mathbf{z}|\\mathbf{x})$.\n",
        "\n",
        "Naturalmente, la elección de $g_{\\phi}$ y $p(\\epsilon)$ condiciona la forma de $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$. Para variables aleatorias contínuas, pensemos en una distribución Gaussiana. Si $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$ es Gaussiana su media y su varianza son (en principio) funciones de $\\mathbf{x}$, es decir\n",
        "\n",
        "\\begin{equation}\n",
        "  q_{\\phi}(\\mathbf{z}|\\mathbf{x}) = \\mathcal{N}(\\mathbf{z};\\mu_{\\mathbf{z}}(\\mathbf{x}), \\Sigma_{\\mathbf{z}}(\\mathbf{x}))\n",
        "\\end{equation}\n",
        "\n",
        "y si, en forma más \"restrictiva\", $\\mathbf{z}$ es un vector aleatorio con componentes descorrelacionadas:\n",
        "\n",
        "\\begin{equation}\n",
        "  q_{\\phi}(\\mathbf{z}|\\mathbf{x}) = \\mathcal{N}(\\mathbf{z};\\mu_{\\mathbf{z}}(\\mathbf{x}),\\sigma_{\\mathbf{z}}^{2}(\\mathbf{x})I)\n",
        "\\end{equation}\n",
        "\n",
        "Eligiendo entonces\n",
        "\n",
        "\\begin{equation}\n",
        "  g_{\\phi}(\\mathbf{x},\\epsilon) = \\mu_{\\mathbf{z}}(\\mathbf{x}) + \\sigma_{\\mathbf{z}}(\\mathbf{x}) \\odot \\epsilon, \\hspace{5mm} \\epsilon \\sim \\mathcal{N}(\\epsilon,0,I)\n",
        "\\end{equation}\n",
        "\n",
        "se satisface la condición deseada. Notar que la operación $\\odot$ denota el producto punto a punto entre dos vectores.\n",
        "\n",
        "En forma más conceptual se puede decir que lo que hace el *Reparametrization Trick* es escalar y trasladar un ruido $\\epsilon$ de modo que estadísticamente se comporte como una variable aleatoria Gaussiana de parámetros $\\mu_{\\mathbf{z}}(\\mathbf{x}), \\Sigma_{\\mathbf{z}}(\\mathbf{x})$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoYP-r5pNiWe",
        "colab_type": "text"
      },
      "source": [
        "###### Demostración"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30UZtQrkNj1W",
        "colab_type": "text"
      },
      "source": [
        "Según el *Reparametrization Trick* se tiene que\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    q_{\\phi}(\\mathbf{z}|\\mathbf{x})d\\mathbf{z} &= q_{\\phi}(\\mathbf{z}|\\mathbf{x})\\prod_{j=1}^{J}dz_{j} \\\\\n",
        "    &= p(\\epsilon)\\prod_{j=1}^{J}d\\epsilon_{j} \\\\\n",
        "    &= p(\\epsilon)d\\epsilon\n",
        "  \\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Luego, para la media de $\\mathbf{Z}$\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    \\mathbb{E}_{\\mathbf{Z} \\sim q_{\\phi}(\\mathbf{z}|\\mathbf{x})}\\left\\{\\mathbf{z}\\right\\} &= \\int_{\\mathcal{Z}}\\mathbf{z}q_{\\phi}(\\mathbf{z}|\\mathbf{x})d\\mathbf{z} \\\\\n",
        "    &= \\int_{\\mathbb{R}^{J}}g_{\\phi}(\\mathbf{x},\\epsilon)p(\\epsilon)d\\epsilon \\\\\n",
        "    &= \\int_{\\mathbb{R}^{J}}(\\mu_{\\mathbf{z}}(\\mathbf{x}) + \\sigma_{\\mathbf{z}}(\\mathbf{x}) \\odot \\epsilon)p(\\epsilon)d\\epsilon \\\\\n",
        "    &= \\mu_{\\mathbf{z}}(\\mathbf{x}) + \\sigma_{\\mathbf{z}}(\\mathbf{x}) \\odot \\int_{\\mathbb{R}^{J}}\\epsilon p(\\epsilon)d\\epsilon \\\\\n",
        "    &= \\mu_{\\mathbf{z}}(\\mathbf{x})\n",
        "  \\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "y para su varianza\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    Var_{\\mathbf{Z} \\sim q_{\\phi}(\\mathbf{z}|\\mathbf{x})}(\\mathbf{z}) &= \\mathbb{E}_{\\mathbf{Z} \\sim q_{\\phi}(\\mathbf{z}|\\mathbf{x})}\\left\\{(\\mathbf{z} - \\mu_{\\mathbf{z}}(\\mathbf{x}))^{2}\\right\\} \\\\\n",
        "    &= \\int_{\\mathcal{Z}}(\\mathbf{z} - \\mu_{\\mathbf{z}}(\\mathbf{x}))^{2}q_{\\phi}(\\mathbf{z}|\\mathbf{x})d\\mathbf{z} \\\\\n",
        "    &= \\int_{\\mathbb{R}^{J}}(g_{\\phi}(\\mathbf{x},\\epsilon) - \\mu_{\\mathbf{z}}(\\mathbf{x}))^{2}p(\\epsilon)d\\epsilon \\\\\n",
        "    &= \\int_{\\mathbb{R}^{J}}(\\mu_{\\mathbf{z}}(\\mathbf{x}) + \\sigma_{\\mathbf{z}}(\\mathbf{x}) \\odot \\epsilon - \\mu_{\\mathbf{z}}(\\mathbf{x}))^{2}p(\\epsilon)d\\epsilon \\\\\n",
        "    &= \\int_{\\mathbb{R}^{J}}\\sigma_{\\mathbf{z}}^{2}(\\mathbf{x}) \\odot \\epsilon^{2}p(\\epsilon)d\\epsilon \\\\\n",
        "    &= \\sigma_{\\mathbf{z}}^{2}(\\mathbf{x}) \\odot \\int_{\\mathbb{R}^{J}}\\epsilon^{2}p(\\epsilon)d\\epsilon \\\\\n",
        "    &= \\sigma_{\\mathbf{z}}^{2}(\\mathbf{x})I\n",
        "  \\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Finalmente, como una distribución Gaussiana está caracterizada completamente por su media y su varianza se concluye que $q_{\\phi}(\\mathbf{z}|\\mathbf{x}) = \\mathcal{N}(\\mathbf{z};\\mu_{\\mathbf{z}}(\\mathbf{x}),\\sigma_{\\mathbf{z}}^{2}(\\mathbf{x})I)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz64lTPsNrIG",
        "colab_type": "text"
      },
      "source": [
        "###### Y luego..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlvwyndINrq3",
        "colab_type": "text"
      },
      "source": [
        "Bajo este tipo de supuestos es posible muestrear la variable aleatoria latente para cada punto en $\\mathcal{X}$, es decir (y en particular) $\\forall \\mathbf{x}^{(i)} \\in \\left\\{\\mathbf{x}^{(i)}\\right\\}_{i=1}^{N}$ se puede muestrear un conjunto $\\left\\{\\mathbf{z}^{(i,l)}:\\mathbf{z}^{(i,l)} \\sim q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})\\right\\}_{l=1}^{L}$, con lo cual es posible aproximar dicha distribución condicional en forma empírica según\n",
        "\n",
        "\\begin{equation}\n",
        "  q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)}) \\approx \\frac{1}{L}\\sum_{l=1}^{L}\\delta_{\\mathbf{z}^{(i,l)}}(\\mathbf{z}) \\tag{5}\n",
        "\\end{equation}\n",
        "\n",
        "y por ende\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    \\mathbb{E}_{\\mathbf{Z} \\sim q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})}\\left\\{\\log p_{\\theta}(\\mathbf{x}^{(i)}|\\mathbf{z})\\right\\} &= \\int_{\\mathcal{Z}}\\log p_{\\theta}(\\mathbf{x}^{(i)}|\\mathbf{z})q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})d\\mathbf{z} \\\\\n",
        "    &\\approx \\int_{\\mathcal{Z}}\\log p_{\\theta}(\\mathbf{x}^{(i)}|\\mathbf{z}) \\frac{1}{L}\\sum_{l=1}^{L}\\delta_{\\mathbf{z}^{(i,l)}}(\\mathbf{z})d\\mathbf{z} \\\\\n",
        "    &= \\frac{1}{L}\\sum_{l=1}^{L}\\log p_{\\theta}(\\mathbf{x}^{(i)}|\\mathbf{z}^{(i,l)})\n",
        "  \\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Luego, esta esperanza aproximada se puede reemplazar en la expresión para el funcional $\\mathcal{L}(\\phi,\\theta,\\mathbf{x}^{(i)})$ de la ecuación $(4)$ que acota la *log-likelihood* marginal del punto $\\mathbf{x}^{(i)}$:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    \\log p_{\\theta^{*}}(\\mathbf{x}^{(i)}) &\\geq \\mathcal{L}(\\phi,\\theta,\\mathbf{x}^{(i)}) \\\\\n",
        "    &= \\frac{1}{L}\\sum_{l=1}^{L}\\log p_{\\theta}(\\mathbf{x}^{(i)}|\\mathbf{z}^{(i,l)}) - KL\\left(q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})||p_{\\theta}(\\mathbf{z})\\right)\n",
        "  \\end{split} \\tag{6}\n",
        "\\end{equation}\n",
        "\n",
        "El hecho de haber utilizado el *Reparametrization Trick* nos permite, además, tratar en forma cerrada la divergencia que aparece en el segundo termino de este funcional, dado un *prior* $p_{\\theta}(\\mathbf{z})$. Esto es así pues en el proceso se asumió la forma de la distribución $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    KL\\left(q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})||p_{\\theta}(\\mathbf{z})\\right) &= \\int_{\\mathcal{Z}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)}) \\log \\frac{q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})}{p_{\\theta}(\\mathbf{z})}d\\mathbf{z} \\\\\n",
        "    &= \\int_{\\mathcal{Z}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})\\log q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})d\\mathbf{z} - \\int_{\\mathcal{Z}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})\\log p_{\\theta}(\\mathbf{z})d\\mathbf{z} \\\\\n",
        "    &\\triangleq I_{1} - I_{2}\n",
        "  \\end{split} \\tag{7}\n",
        "\\end{equation}\n",
        "\n",
        "Resolviendo primeramente para la integral $I_{1}$:\n",
        "\n",
        "> \\begin{equation}\n",
        "    \\begin{split}\n",
        "      I_{1} &= \\int_{\\mathcal{Z}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)}) \\log q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})d\\mathbf{z} \\\\\n",
        "      &= \\int_{\\mathbb{R}^{J}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})\\log \\left((2\\pi)^{\\frac{-J}{2}} \\cdot |\\Sigma_{\\mathbf{z}}(\\mathbf{x}^{(i)})|^{\\frac{-1}{2}} \\cdot \\exp\\left(-\\frac{1}{2}(\\mathbf{z} - \\mu_{\\mathbf{z}}(\\mathbf{x}^{(i)}))^{\\intercal}\\Sigma_{\\mathbf{z}}^{-1}(\\mathbf{x}^{(i)})(\\mathbf{z} - \\mu_{\\mathbf{z}}(\\mathbf{x}^{(i)}))\\right)\\right)d\\mathbf{z}\n",
        "    \\end{split}\n",
        "  \\end{equation}\n",
        "\n",
        "> Si, como se dijo anteriormente, se considera que $\\Sigma_{\\mathbf{z}}(\\mathbf{x}^{(i)})$ es una matriz diagonal es posible reducir esta expresión fácilmente:\n",
        "\n",
        "> \\begin{equation}\n",
        "    \\begin{split}\n",
        "      I_{1} &= \\int_{\\mathbb{R}^{J}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})\\left[\\log \\left((2\\pi)^{\\frac{-J}{2}} \\cdot \\left(\\prod_{j=1}^{J}\\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})\\right)^{\\frac{-1}{2}}\\right) + -\\frac{1}{2}\\sum_{j=1}^{J}\\frac{(z_{j} - \\mu_{z_{j}}(\\mathbf{x}^{(i)}))^{2}}{\\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})}\\right]d\\mathbf{z} \\\\\n",
        "      &= \\left(-\\frac{J}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{j=1}^{J}\\log \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})\\right)\\int_{\\mathbb{R}^{J}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})d\\mathbf{z} + -\\frac{1}{2}\\int_{\\mathbb{R}^{J}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})\\sum_{j=1}^{J}\\frac{(z_{j} - \\mu_{z_{j}}(\\mathbf{x}^{(i)}))^{2}}{\\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})}d\\mathbf{z} \\\\\n",
        "      &= -\\frac{J}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{j=1}^{J}\\log \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)}) + -\\frac{1}{2}\\sum_{j=1}^{J}\\frac{\\int_{\\mathbb{R}}q_{\\phi}(z_{j}|\\mathbf{x}^{(i)})(z_{j} - \\mu_{z_{j}}(\\mathbf{x}^{(i)}))^{2}dz_{j}}{\\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})} \\\\\n",
        "      &= -\\frac{J}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{j=1}^{J}\\log \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)}) + -\\frac{1}{2}\\sum_{j=1}^{J}\\frac{\\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})}{\\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})} \\\\\n",
        "      &= -\\frac{J}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{j=1}^{J}1 + \\log \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})\n",
        "    \\end{split} \\tag{8}\n",
        "  \\end{equation}\n",
        "\n",
        ">> **Nota**: Para el caso más general puede ser útil este [enlace](https://sgfin.github.io/2017/03/11/Deriving-the-information-entropy-of-the-multivariate-gaussian/).\n",
        "\n",
        "Como bien se dijo anteriormente, para resolver analíticamente esta divergencia es necesario introducir un *prior* $p_{\\theta}(\\mathbf{z})$. Si se elige $p_{\\theta}(\\mathbf{z}) = \\mathcal{N}(\\mathbf{z}; 0, I)$, la integral $I_{2}$ se resuelve como:\n",
        "\n",
        "> \\begin{equation}\n",
        "    \\begin{split}\n",
        "      I_{2} &= \\int_{\\mathcal{Z}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)}) \\log p_{\\theta}(\\mathbf{z}) d\\mathbf{z} \\\\\n",
        "      &= \\int_{\\mathbb{R}^{J}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)}) \\log \\left((2\\pi)^{\\frac{-J}{2}} \\cdot |I|^{\\frac{-1}{2}} \\cdot \\exp \\left(-\\frac{1}{2}\\mathbf{z}^{\\intercal}I^{-1}\\mathbf{z}\\right)\\right) d\\mathbf{z} \\\\\n",
        "      &= \\int_{\\mathbb{R}^{J}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)}) \\log \\left((2\\pi)^{\\frac{-J}{2}} \\cdot \\prod_{j=1}^{J}1 \\cdot \\exp \\left(-\\frac{1}{2}\\mathbf{z}^{\\intercal}\\mathbf{z}\\right)\\right) d\\mathbf{z} \\\\\n",
        "      &= \\int_{\\mathbb{R}^{J}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)}) \\left[-\\frac{J}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{j=1}^{J}\\log 1 + -\\frac{1}{2}\\mathbf{z}^{\\intercal}\\mathbf{z}\\right] d\\mathbf{z} \\\\\n",
        "      &= -\\frac{J}{2}\\log 2\\pi + -\\frac{1}{2}\\int_{\\mathbb{R}^{J}}q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})\\sum_{j=1}^{J}z_{j}^{2} d\\mathbf{z} \\\\\n",
        "      &= -\\frac{J}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{j=1}^{J}\\int_{\\mathbb{R}}z_{j}^{2}q_{\\phi}(z_{j}|\\mathbf{x}^{(i)}) dz_{j} \\\\\n",
        "      &= -\\frac{J}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{j=1}^{J}\\mu_{z_{j}}^{2}(\\mathbf{x}^{(i)}) + \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)}) \n",
        "    \\end{split} \\tag{9}\n",
        "  \\end{equation}\n",
        "\n",
        "Finalmente, reemplazamos ambas integrales ($(8)$ y $(9)$) en la expresión de la ecuación $(7)$, con lo cual\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    KL\\left(q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)})||p_{\\theta}(\\mathbf{z})\\right) &= -\\frac{J}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{j=1}^{J}1 + \\log \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)}) - \\left(-\\frac{J}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{j=1}^{J}\\mu_{z_{j}}^{2}(\\mathbf{x}^{(i)}) + \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})\\right) \\\\\n",
        "    &= -\\frac{1}{2}\\sum_{j=1}^{J}1+\\log \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)}) - \\mu_{z_{j}}^{2}(\\mathbf{x}^{(i)}) - \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})\n",
        "  \\end{split} \\tag{10}\n",
        "\\end{equation}\n",
        "\n",
        "Con esto, el funcional $\\mathcal{L}(\\phi,\\theta,\\mathbf{x}^{(i)})$ se puede escribir como\n",
        "\n",
        "\\begin{equation}\n",
        "  \\mathcal{L}(\\phi,\\theta,\\mathbf{x}^{(i)}) = \\frac{1}{L}\\sum_{l=1}^{L}\\log p_{\\theta}(\\mathbf{x}^{(i)}|\\mathbf{z}^{(i,l)}) + \\frac{1}{2}\\sum_{j=1}^{J}1 + \\log \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)}) - \\mu_{z_{j}}^{2}(\\mathbf{x}^{(i)}) - \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)}) \\tag{11}\n",
        "\\end{equation}\n",
        "\n",
        "De la misma forma que establecer es supuesto de Gaussianidad sobre el *encoder* permite encontrar en forma cerrada una expresión para la divergencia $KL\\left(q_{\\phi}(\\mathbf{z}|\\mathbf{x}^{(i)}||p_{\\theta}(\\mathbf{z}))\\right)$, es posible hacer supuestos sobre el *decoder* para tratar el término $\\log p_{\\theta}(\\mathbf{x}^{(i)}|\\mathbf{z}^{(i,l)})$.\n",
        "\n",
        "Para un *decoder* Gaussiano que parametriza $\\mathbf{x}$ por la media $\\mu_{\\mathbf{x}}(\\mathbf{z})$ y la varianza $\\Sigma_{\\mathbf{x}}(\\mathbf{z})$ es posible escribir la *log-likelihood* como sigue:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    \\log p_{\\theta}(\\mathbf{x}^{(i)}|\\mathbf{z}^{(i,l)}) &= \\log \\left(\\mathcal{N}(\\mathbf{x}^{(i)};\\mu_{\\mathbf{x}}(\\mathbf{z}^{(i,l)})), \\Sigma_{\\mathbf{x}}(\\mathbf{z}^{(i,l)})\\right) \\\\\n",
        "    &= \\log \\left((2\\pi)^{\\frac{-K}{2}} \\cdot |\\Sigma_{\\mathbf{x}}(\\mathbf{z}^{(i,l)})|^{\\frac{-1}{2}} \\cdot \\exp \\left(-\\frac{1}{2}(\\mathbf{x}^{(i)} - \\mu_{\\mathbf{x}}(\\mathbf{z}^{(i,l)}))^{\\intercal} \\Sigma_{\\mathbf{x}}^{-1}(\\mathbf{z}^{(i,l)})(\\mathbf{x}^{(i)} - \\mu_{\\mathbf{x}}(\\mathbf{z}^{(i,l)}))\\right)\\right) \\\\\n",
        "    &= -\\frac{K}{2}\\log 2\\pi + -\\frac{1}{2}\\log |\\Sigma_{\\mathbf{x}}(\\mathbf{z}^{(i,l)})| + -\\frac{1}{2}(\\mathbf{x}^{(i)} - \\mu_{\\mathbf{x}}(\\mathbf{z}^{(i,l)}))^{\\intercal}\\Sigma_{\\mathbf{x}}^{-1}(\\mathbf{z}^{(i,l)})(\\mathbf{x}^{(i)} - \\mu_{\\mathbf{x}}(\\mathbf{z}^{(i,l)}))\n",
        "  \\end{split} \\tag{12}\n",
        "\\end{equation}\n",
        "\n",
        "Si nuevamente se asume descorrelación entre las distintas componentes de $\\mathbf{X}$, la expresión anterior se reduce a:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    \\log p_{\\theta}(\\mathbf{x}^{(i)}|\\mathbf{z}^{(i,l)}) &= -\\frac{K}{2} \\log 2\\pi + -\\frac{1}{2}\\log \\prod_{k=1}^{K}\\sigma_{x_{k}}^{2}(\\mathbf{z}^{(i,l)}) + -\\frac{1}{2}\\sum_{k=1}^{K}\\frac{(x_{k}^{(i)} - \\mu_{x_{k}}(\\mathbf{z}^{(i,l)}))^{2}}{\\sigma_{x_{k}}^{2}(\\mathbf{z}^{(i,l)})} \\\\\n",
        "    &= -\\frac{K}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{k=1}^{K}\\log \\sigma_{x_{k}}^{2}(\\mathbf{z}^{(i,l)}) + -\\frac{1}{2}\\sum_{k=1}^{K}\\frac{(x_{k}^{(i)} - \\mu_{x_{k}}(\\mathbf{z}^{(i,l)}))^{2}}{\\sigma_{x_{k}}^{2}(\\mathbf{z}^{(i,l)})} \\\\\n",
        "    &= -\\frac{K}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{k=1}^{K}\\log\\sigma_{x_{k}}^{2}(\\mathbf{z}^{(i,l)}) + \\frac{(x_{k}^{(i)} - \\mu_{x_{k}}(\\mathbf{z}^{(i,l)}))^{2}}{\\sigma_{x_{k}}^{2}(\\mathbf{z}^{(i,l)})}\n",
        "  \\end{split} \\tag{13}\n",
        "\\end{equation}\n",
        "\n",
        "Así, el funcional de costo por cada punto $\\mathbf{x}^{(i)}$ de las ecuaciones $(4)$ y $(11)$ resulta en:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    \\mathcal{L}(\\phi,\\theta,\\mathbf{x}^{(i)}) &= \\frac{1}{L}\\sum_{l=1}^{L}\\left[-\\frac{K}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{k=1}^{K}\\log\\sigma_{x_{k}}^{2}(\\mathbf{z}^{(i,l)}) + \\frac{(x_{k}^{(i)} - \\mu_{x_{k}}(\\mathbf{z}^{(i,l)}))^{2}}{\\sigma_{x_{k}}^{2}(\\mathbf{z}^{(i,l)})}\\right] \\\\\n",
        "  &\\hspace{5mm} + \\frac{1}{2}\\sum_{j=1}^{J}1 + \\log \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)}) - \\mu_{z_{j}}^{2}(\\mathbf{x}^{(i)}) - \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})\n",
        "  \\end{split} \\tag{14}\n",
        "\\end{equation}\n",
        "\n",
        "Otro aspecto a considerar es que, a diferencia de muchos otros modelos de *Deep Learning*, el entrenamiento de este modelo por medio de *batches* no es sobre la esperanza de la función de pérdida $\\mathcal{L}(\\phi,\\theta,\\mathbf{x})$. \n",
        "\n",
        "Para verificar esto consideremos un *batch* de $M \\leq N$ muestras de $X$, es decir $\\left\\{\\mathbf{x}^{(i)}\\right\\}_{i=1}^{M} \\subseteq \\mathcal{X}$. La *log-likelihood* marginal de este conjunto de datos está dada por:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    \\log p_{\\theta^{*}}(\\mathbf{x}^{(1)},\\dots,\\mathbf{x}^{(M)}) &= \\log\\prod_{i=1}^{M}p(\\mathbf{x}^{(i)}) \\\\\n",
        "    &= \\sum_{i=1}^{M}\\log p(\\mathbf{x}^{(i)}) \\\\\n",
        "    &\\geq \\sum_{i=1}^{M}\\mathcal{L}(\\phi,\\theta,\\mathbf{x}^{(i)})\n",
        "  \\end{split} \\tag{15}\n",
        "\\end{equation}\n",
        "\n",
        "De esta forma podemos, finalmente, generalizar la función de pérdida para entrenar la red del *Autoencoder* Variacional:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\begin{split}\n",
        "    \\mathcal{L}\\left(\\phi,\\theta,\\{\\mathbf{x}^{(i)}\\}_{i=1}^{M}\\right) &\\triangleq \\sum_{i=1}^{M}\\mathcal{L}(\\phi,\\theta,\\mathbf{x}^{(i)}) \\\\\n",
        "    &= \\sum_{i=1}^{M}\\Bigg[\\frac{1}{L}\\sum_{l=1}^{L}-\\frac{K}{2}\\log 2\\pi + -\\frac{1}{2}\\sum_{k=1}^{K}\\log\\sigma_{x_{k}}^{2}(\\mathbf{z}^{(i,l)}) + \\frac{(x_{k}^{(i)} - \\mu_{x_{k}}(\\mathbf{z}^{(i,l)}))^{2}}{\\sigma_{x_{k}}^{2}(\\mathbf{z}^{(i,l)})} \\\\\n",
        "    &\\hspace{17mm} + \\frac{1}{2}\\sum_{j=1}^{J}1 + \\log \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)}) - \\mu_{z_{j}}^{2}(\\mathbf{x}^{(i)}) - \\sigma_{z_{j}}^{2}(\\mathbf{x}^{(i)})\\Bigg]\n",
        "  \\end{split} \\tag{16}\n",
        "\\end{equation}\n",
        "\n",
        "> **Nota**: Recordar que el objetivo es **maximizar**  este funcional de costo. Dado que los optimizadores usualmente están pensados para **minimizar** funciones de costo debemos implementar el negativo de este funcional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfRJEnMdNyF5",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, nuestro modelo de *Autoencoder* Variacional se ve en la práctica como en el siguiente esquema:\n",
        "\n",
        "$\\hspace{0mm}$\n",
        "\n",
        "![texto alternativo](https://drive.google.com/uc?id=1MDJf3j2Z2jh6zSoWNQDP1EUKjLn9u1zC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ2sOS8uwP0W",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.2.- Experimentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22kutfkxwe_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "  '''Variational Autoencoder model with Gaussian Encoder and Decoder'''\n",
        "  def __init__(self, zDim, sampling = 1):\n",
        "    super(VAE, self).__init__()\n",
        "    self.sampling = sampling\n",
        "    hDim = 1500\n",
        "\n",
        "    ## Encoder\n",
        "    self.fc1 = nn.Sequential(nn.Linear(784, hDim),\n",
        "                             nn.ReLU())             ## Nonlinear layer\n",
        "    \n",
        "    self.encoder_mu = nn.Linear(hDim, zDim)         ## Encoder for mu\n",
        "    self.encoder_logvar = nn.Linear(hDim, zDim)     ## Encoder for log-variance                              \n",
        "\n",
        "    ## Decoder\n",
        "    self.fc2 = nn.Sequential(nn.Linear(zDim, hDim),\n",
        "                             nn.ReLU())         ## Nonlinear layer\n",
        "    \n",
        "    self.decoder_mu = nn.Linear(hDim, 784)          ## Decoder for mu\n",
        "    self.decoder_logvar = nn.Linear(hDim, 784)      ## Decoder for log-variance\n",
        "\n",
        "\n",
        "  def encode(self, x):\n",
        "    '''Make inferece of the latent variables Z for X'''\n",
        "    x = self.fc1(x)\n",
        "    mu = self.encoder_mu(x)\n",
        "    logvar = self.encoder_logvar(x)\n",
        "    return mu, logvar\n",
        "\n",
        "  def reparametrize(self, mu, logvar):\n",
        "    '''Reparametrization is required for aproximating expectations during\n",
        "    training'''\n",
        "    L = self.sampling\n",
        "    sigma = torch.exp(0.5 * logvar)\n",
        "    if not self.training:\n",
        "      L = 1\n",
        "    epsilon = torch.randn(list(mu.shape)+[L]).cuda()\n",
        "    mu = mu.view(list(mu.shape)+[1])\n",
        "    sigma = sigma.view(list(sigma.shape)+[1])\n",
        "    z = mu + sigma * epsilon \n",
        "    z_ = z.permute(0,2,1)\n",
        "    return z_\n",
        "\n",
        "  def decode(self, z):\n",
        "    '''Reconstruct X from the latent space variables'''\n",
        "    z = self.fc2(z)\n",
        "    mu = self.decoder_mu(z)\n",
        "    logvar = self.decoder_logvar(z)\n",
        "    return mu, logvar\n",
        "\n",
        "  def forward(self, x):\n",
        "    mu_z, logvar_z = self.encode(x)\n",
        "    z = self.reparametrize(mu_z, logvar_z)\n",
        "\n",
        "    mu_x, logvar_x = self.decode(z)\n",
        "    return mu_z, logvar_z, mu_x, logvar_x\n",
        "\n",
        "  def VAELoss(self, x, mu_z, logvar_z, mu_x, logvar_x):\n",
        "    '''Caculate the loss for VAE with Gaussian Encoder and Decoder'''\n",
        "    K = x.shape[-1]           ## Get dimensionality of X (since it's flattened)\n",
        "    L = self.sampling         ## Number of samples to take for each value x\n",
        "    \n",
        "    var_z = torch.exp(0.5 * logvar_z)\n",
        "    var_x = torch.exp(0.5 * logvar_x)\n",
        "    \n",
        "    ## Sum over J\n",
        "    Jterm = 1 + torch.log(var_z) - (mu_z ** 2) - var_z\n",
        "    Jterm = 0.5 * Jterm.sum(axis = -1).reshape(-1)   ## Get rid of \"extra\"\n",
        "                                                     ## dimension\n",
        "    ## Sum over K\n",
        "    Kterm = torch.log(var_x) + (((x - mu_x) ** 2) / var_x)\n",
        "    Kterm = 0.5 * Kterm.sum(axis = -1)\n",
        "    \n",
        "    ## Sum over L\n",
        "    Kterm =  -0.5 * K * np.log(2 * np.pi) - Kterm\n",
        "    Lterm =  Kterm.sum(axis = -1) / L\n",
        "\n",
        "    ## Sum over M\n",
        "    Mterm = Lterm + Jterm\n",
        "    loss = Mterm.sum()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def fVAELoss(x, mu_z, logvar_z, mu_x, logvar_x, sampling = 1):\n",
        "  '''Caculate the loss for VAE with Gaussian Encoder and Decoder'''\n",
        "  K = x.shape[-1]           ## Get dimensionality of X (since it's flattened)\n",
        "  L = sampling              ## Number of samples to take for each value x\n",
        "  \n",
        "  var_z = torch.exp(0.5 * logvar_z)\n",
        "  var_x = torch.exp(0.5 * logvar_x)\n",
        "  \n",
        "  ## Sum over J\n",
        "  Jterm = 1 + torch.log(var_z) - (mu_z ** 2) - var_z\n",
        "  Jterm = 0.5 * Jterm.sum(axis = 1).reshape(-1)\n",
        "                       \n",
        "  ## Sum over K\n",
        "  Kterm = torch.log(var_x) + (((x.view([x.shape[0],1,x.shape[1]]) - mu_x) ** 2) / var_x)\n",
        "  Kterm = 0.5 * Kterm.sum(axis = 1)\n",
        "  \n",
        "  ## Sum over L\n",
        "  Kterm =  -0.5 * K * np.log(2 * np.pi) - Kterm\n",
        "  Lterm =  Kterm.sum(axis = -1) / L\n",
        "\n",
        "  ## Sum over M\n",
        "  Mterm = Lterm + Jterm\n",
        "  loss = Mterm.sum()\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flEucvoIw4Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr0 = 10e-4\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "lr_decay = 0.97\n",
        "decay_rate = 2\n",
        "\n",
        "nEpochs = 60\n",
        "\n",
        "zDim = 50\n",
        "model = VAE(zDim = zDim, sampling = 50).cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr0, (beta1, beta2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdO6yAqww_JE",
        "colab_type": "code",
        "outputId": "bd2aae87-39b3-4159-e223-0c76afe5afc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('Reference images:')\n",
        "img1 = val_loader_mnist.dataset[15][0].numpy()[0]\n",
        "img2 = val_loader_mnist.dataset[29][0].numpy()[0]\n",
        "img3 = val_loader_mnist.dataset[54][0].numpy()[0]\n",
        "img = np.hstack((img1, np.hstack((img2, img3))))\n",
        "plt.figure()\n",
        "plt.imshow(img,cmap=cm.gray)\n",
        "plt.show()\n",
        "print('Max value: {}, Min value: {}\\n'.format(np.amax(img), np.amin(img)))\n",
        "img1 = torch.from_numpy(img1).reshape(-1,1,784).cuda()\n",
        "img2 = torch.from_numpy(img2).reshape(-1,1,784).cuda()\n",
        "img3 = torch.from_numpy(img3).reshape(-1,1,784).cuda()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(nEpochs):\n",
        "  for i, (x_b, y_b) in enumerate(train_loader_mnist):\n",
        "    x_b = x_b.reshape(train_batch_size, -1).cuda()\n",
        "    \n",
        "    optimizer.zero_grad()           ## No olvidar resetear los gradientes\n",
        "\n",
        "    mu_z, logvar_z, mu_x, logvar_x = model.forward(x_b)\n",
        "\n",
        "    #loss = -1 *  model.VAELoss(x_b, mu_z, logvar_z, mu_x, logvar_x)\n",
        "    loss = -1 *  fVAELoss(x_b, mu_z, logvar_z, mu_x, logvar_x, sampling = model.sampling)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    #print('Epoch : {} , Step : {}|| Loss : {:.3f}'.format(epoch + 1, i + 1, loss))\n",
        "\n",
        "  print('Epoch : {} || Loss : {:.3f}'.format(epoch + 1, loss))\n",
        "\n",
        "  if epoch % decay_rate == 1:\n",
        "    optimizer.param_groups[0]['lr'] *= lr_decay\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    example = model.fc1[0].weight.grad\n",
        "    #print(model.fc1[0].weight.grad)\n",
        "    #print(model.encoder_mu.weight.grad)\n",
        "    #print(model.fc2[0].weight)\n",
        "    model.eval()\n",
        "    print('Reconstructions:')\n",
        "    c_img1 = img1.view(1,-1)\n",
        "    _, _, rec1, _ = model.forward(c_img1)\n",
        "    rec1 = rec1.cpu().detach().numpy().reshape(28,28)\n",
        "    c_img2 = img2.view(1,-1)\n",
        "    _, _, rec2, _ = model.forward(c_img2)\n",
        "    rec2 = rec2.cpu().detach().numpy().reshape(28,28)\n",
        "    c_img3 = img3.view(1,-1)\n",
        "    _, _, rec3, _ = model.forward(c_img3)\n",
        "    rec3 = rec3.cpu().detach().numpy().reshape(28,28)\n",
        "    img = np.hstack((rec1, np.hstack((rec2, rec3))))\n",
        "    plt.figure()\n",
        "    plt.imshow(img,cmap=cm.gray)\n",
        "    plt.show()\n",
        "    print('Max value: {}, Min value: {}\\n'.format(np.amax(img), np.amin(img)))\n",
        "    model.train()\n",
        "\n",
        "model.eval()\n",
        "print('Reconstructions:')\n",
        "c_img1 = img1.view(1,-1)\n",
        "_, _, rec1, _ = model.forward(c_img1)\n",
        "rec1 = rec1.cpu().detach().numpy().reshape(28,28)\n",
        "c_img2 = img2.view(1,-1)\n",
        "_, _, rec2, _ = model.forward(c_img2)\n",
        "rec2 = rec2.cpu().detach().numpy().reshape(28,28)\n",
        "c_img3 = img3.view(1,-1)\n",
        "_, _, rec3, _ = model.forward(c_img3)\n",
        "rec3 = rec3.cpu().detach().numpy().reshape(28,28)\n",
        "img = np.hstack((rec1, np.hstack((rec2, rec3))))\n",
        "plt.figure()\n",
        "plt.imshow(img,cmap=cm.gray)\n",
        "plt.show()\n",
        "print('Max value: {}, Min value: {}\\n'.format(np.amax(img), np.amin(img)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reference images:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max value: 1.0, Min value: 0.0\n",
            "\n",
            "Epoch : 1 || Loss : 1018894.750\n",
            "Reconstructions:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max value: 1.1269128322601318, Min value: -0.2730417251586914\n",
            "\n",
            "Epoch : 2 || Loss : 1038846.188\n",
            "Epoch : 3 || Loss : 1008622.250\n",
            "Epoch : 4 || Loss : 983635.875\n",
            "Epoch : 5 || Loss : 986684.875\n",
            "Epoch : 6 || Loss : 970314.000\n",
            "Epoch : 7 || Loss : 983156.250\n",
            "Epoch : 8 || Loss : 953743.188\n",
            "Epoch : 9 || Loss : 960358.500\n",
            "Epoch : 10 || Loss : 950003.250\n",
            "Epoch : 11 || Loss : 944289.625\n",
            "Reconstructions:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max value: 1.4649262428283691, Min value: -0.33608654141426086\n",
            "\n",
            "Epoch : 12 || Loss : 935413.375\n",
            "Epoch : 13 || Loss : 938408.750\n",
            "Epoch : 14 || Loss : 967693.750\n",
            "Epoch : 15 || Loss : 1206257.250\n",
            "Epoch : 16 || Loss : 920320.062\n",
            "Epoch : 17 || Loss : 912927.750\n",
            "Epoch : 18 || Loss : 944187.625\n",
            "Epoch : 19 || Loss : 905042.750\n",
            "Epoch : 20 || Loss : 960760.625\n",
            "Epoch : 21 || Loss : 902796.250\n",
            "Reconstructions:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max value: 1.3617515563964844, Min value: -0.3717353045940399\n",
            "\n",
            "Epoch : 22 || Loss : 932944.688\n",
            "Epoch : 23 || Loss : 889986.750\n",
            "Epoch : 24 || Loss : 894173.625\n",
            "Epoch : 25 || Loss : 897274.062\n",
            "Epoch : 26 || Loss : 888365.188\n",
            "Epoch : 27 || Loss : 895065.750\n",
            "Epoch : 28 || Loss : 1134656.125\n",
            "Epoch : 29 || Loss : 877503.250\n",
            "Epoch : 30 || Loss : 879101.062\n",
            "Epoch : 31 || Loss : 871378.375\n",
            "Reconstructions:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max value: 1.4379632472991943, Min value: -0.3636403977870941\n",
            "\n",
            "Epoch : 32 || Loss : 892916.812\n",
            "Epoch : 33 || Loss : 904451.438\n",
            "Epoch : 34 || Loss : 907892.875\n",
            "Epoch : 35 || Loss : 1064919.500\n",
            "Epoch : 36 || Loss : 866079.188\n",
            "Epoch : 37 || Loss : 884837.062\n",
            "Epoch : 38 || Loss : 897275.625\n",
            "Epoch : 39 || Loss : 863509.875\n",
            "Epoch : 40 || Loss : 860597.000\n",
            "Epoch : 41 || Loss : 868227.875\n",
            "Reconstructions:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max value: 1.4112797975540161, Min value: -0.4833639860153198\n",
            "\n",
            "Epoch : 42 || Loss : 861178.250\n",
            "Epoch : 43 || Loss : 925843.188\n",
            "Epoch : 44 || Loss : 1010981.125\n",
            "Epoch : 45 || Loss : 865549.375\n",
            "Epoch : 46 || Loss : 873110.625\n",
            "Epoch : 47 || Loss : 860494.062\n",
            "Epoch : 48 || Loss : 853986.875\n",
            "Epoch : 49 || Loss : 852838.562\n",
            "Epoch : 50 || Loss : 866652.875\n",
            "Epoch : 51 || Loss : 862580.375\n",
            "Reconstructions:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max value: 1.544982671737671, Min value: -0.39166122674942017\n",
            "\n",
            "Epoch : 52 || Loss : 864510.125\n",
            "Epoch : 53 || Loss : 863189.688\n",
            "Epoch : 54 || Loss : 868467.125\n",
            "Epoch : 55 || Loss : 877833.375\n",
            "Epoch : 56 || Loss : 851093.562\n",
            "Epoch : 57 || Loss : 883739.000\n",
            "Epoch : 58 || Loss : 838225.438\n",
            "Epoch : 59 || Loss : 852405.500\n",
            "Epoch : 60 || Loss : 848073.750\n",
            "Reconstructions:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max value: 1.4787025451660156, Min value: -0.5118438601493835\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtWtptQwWeCu",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.- Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST9ZmlcoWp6z",
        "colab_type": "text"
      },
      "source": [
        "En esta sección discutimos los principios básicos de los *Autoencoders* y su aproximación variacional. Evidentemente la arquitectura vista se puede modificar y sofisticar pero centremosnos en lo que hemos desarrollado hasta ahora:\n",
        "\n",
        "* En Inferencia Variacional vimos cómo podemos aproximar la distribución de las variables latentes $\\mathbf{Z}$ a partir de la variable observable $\\mathbf{X}$ generada por $\\mathbf{Z}$, dado un modelo de verosimilitud $p(\\mathbf{x}|\\mathbf{z})$ y parametrizando la familia de distribuciones sobre $\\mathbf{Z}$.\n",
        "\n",
        "* Relajamos un poco el modelo anterior al considerar que desconocemos el modelo de verosimilitud (denominado como *decoder*) y definimos el problema de encontrar tanto $p(\\mathbf{z}|\\mathbf{x})$ como $p(\\mathbf{x}|\\mathbf{z})$ como uno de inferencia variacional, donde utilizamos redes neuronales para parametrizar nuestras aproximaciones.\n",
        "\n",
        "En ambos casos, asumimos que la variable $\\mathbf{Z}$ define (o es relevante para) el comportamiento estadístico de $\\mathbf{X}$ y es, por lo tanto, una representación comprimida de $\\mathbf{X}$. \n",
        "\n",
        "Podemos entender $\\mathbf{Z}$ como la información relevante para poder generar muestras del fenómeno $\\mathbf{X}$. Entonces es posible hacernos las siguientes preguntas:\n",
        "\n",
        "¿Qué pasa si nuestra tarea ya no fuera poder reconstruir $\\mathbf{X}$ si no que encontrar la información que esta nos puede dar sobre otro proceso o señal $\\mathbf{Y}$? ¿Es entonces $\\mathbf{Z}$ **relevante** para definir o predecir $\\mathbf{Y}$?\n",
        "\n",
        "Este problema puede ser planteado formalmente por medio del *Information Bottleneck*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWRr4mtiUFeI",
        "colab_type": "text"
      },
      "source": [
        "## 3.- *Information Bottleneck*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhwZOTe3UW9j",
        "colab_type": "text"
      },
      "source": [
        "Para ejemplificar la idea anterior veamos este ejemplo \"clásico\": \n",
        "\n",
        "Se desea diagnosticar a un paciente para saber si tiene o no una enfermedad $\\mathbf{Y}$. Para esto contamos con una batería de datos de esta persona, denotados por $\\mathbf{x}$. Estos datos pueden ser su nombre, edad, datos clínicos como resultados de algún exámen reciente, historial familiar, si nació en Talca o en Rancagua, lugar de trabajo, etc.\n",
        "\n",
        "Podemos decir que $\\mathbf{x}$ caracteriza al paciente, pero claramente para la tarea que nos interesa mucha de la información contenida en $\\mathbf{x}$ es irrelevante. Nos gustaría encontrar un nuevo vector de características $\\mathbf{z}$ que defina en mejor manera el estado de la persona y nos entregue solo los datos importantes para poder diagnosticarla.\n",
        "\n",
        "La tarea de encontrar esta información suele denominarse Extracción de Características, *Feature Engineering*, *Representation Learning*, etc.\n",
        "\n",
        "En el paper fundacional del método del *Information Bottleneck* los autores se plantean precisamente este problema. A partir de la pregunta de cuál es la información relevante que una señal provee acerca de otra llegan en forma natural a un problema de codificación, en el cual capturar en un código $\\mathbf{\\tilde{X}}$ dicha información relevante.\n",
        "\n",
        "Visto de esta forma, el problema se puede plantear como uno de *lossy source coding* formalizado en una rama de teoría de la información conocida como *rate-distortion theory*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNxKV8yXVBcC",
        "colab_type": "text"
      },
      "source": [
        "### 3.1.- *Rate-Distortion Theory*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtgSAbnDHtSM",
        "colab_type": "text"
      },
      "source": [
        "#### 3.1.1.- Contexto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwZjoNOiVGqa",
        "colab_type": "text"
      },
      "source": [
        "Consideremos una señal $\\mathbf{X} \\in \\mathcal{X}$ que es nuestra variable observable y el *codebook* $\\tilde{\\mathcal{X}}$ donde vive la variable $\\tilde{\\mathbf{X}}$ que corresponde a un mapeo estocástico de $\\mathbf{X}$ por medio del canal (o *encoder*) $p(\\tilde{\\mathbf{x}}|\\mathbf{x})$.\n",
        "\n",
        "Dado que nos enfrentamos a un problema de codificación con pérdida, el código $\\tilde{\\mathbf{X}}$ no es únicamente decodificable. Esta pérdida está relacionada con la cantidad de símbolos en $\\mathcal{X}$ mapeados a un mismo valor en $\\tilde{\\mathcal{X}}$, la cual en promedio corresponde a $2^{H(\\mathbf{X}|\\tilde{\\mathbf{X}})}$, con\n",
        "\n",
        "\\begin{equation}\n",
        "  H(\\mathbf{X}|\\tilde{\\mathbf{X}}) = -\\sum_{x \\in \\mathcal{X}} p(x) \\sum_{\\tilde{x} \\in \\tilde{\\mathcal{X}}} p(\\tilde{x}|x)\\log p(x|\\tilde{x})\n",
        "\\end{equation}\n",
        "\n",
        "Podemos interpretar entonces que $p(\\tilde{\\mathbf{x}}|\\mathbf{x})$ induce una partición en $\\mathbf{X}$, donde para cada partición asociada a $\\tilde{\\mathbf{X}} = \\tilde{x}$ se requiere (en promedio) de $H(\\mathbf{X}|\\tilde{\\mathbf{X}})$ bits para describir los valores de $\\mathcal{X}$ asociados a dicha partición.\n",
        "\n",
        "Luego, la variable $\\mathbf{X}|\\tilde{\\mathbf{X}}$ requiere en promedio $H(\\mathbf{X}) - H(\\mathbf{X}|\\tilde{\\mathbf{X}}) = I(\\mathbf{X};\\tilde{\\mathbf{X}})$ bits para ser descrita.\n",
        "\n",
        "En este contexto, $I(\\mathbf{X};\\tilde{\\mathbf{X}})$ cuantifica la \"calidad\" de la partición, pues caracteriza la cantidad de información que $\\tilde{\\mathbf{X}}$ posee acerca de $\\mathbf{X}$ y se denomina como la **tasa de información**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bff7zAgCH1eh",
        "colab_type": "text"
      },
      "source": [
        "#### 3.1.2.- Formalización del Problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP2UlqlhH4we",
        "colab_type": "text"
      },
      "source": [
        "En el problema de compresión con pérdida el objetivo es entonces minimizar $I(\\mathbf{X};\\tilde{\\mathbf{X}})$. Evidentemente si no se restrinje el problema se llega a la solución trivial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hXafJ9GMnC_",
        "colab_type": "text"
      },
      "source": [
        "Para evitar esta situación, en *rate-distortion theory* se introduce el concepto de distorsión, dada por la función $d: \\mathcal{X} \\times \\tilde{\\mathcal{X}} \\to \\mathbb{R}^{+} \\cup \\{0\\}$. Dada una partición inducida por $p(\\tilde{\\mathbf{x}}|\\mathbf{x})$ se tendrá una distorsión esperada:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\mathbb{E}_{p(\\mathbf{x},\\tilde{\\mathbf{x}})}\\left\\{d(x,\\tilde{x})\\right\\} = \\sum_{x  \\in \\mathcal{X}} \\sum_{\\tilde{x} \\in \\tilde{\\mathcal{X}}}p(x,\\tilde{x})d(x,\\tilde{x})\n",
        "\\end{equation}\n",
        "\n",
        "Luego, al limitar la distorsión esperada inducida por el *encoder* a un máximo, $D$, se tiene una formulación mucho más interesante del problema, planteado ahora por medio de la función $R(D)$ correspondiente a la tasa de información mínima asociada a la pérdida $D$:\n",
        "\n",
        "\\begin{equation}\n",
        "R(D) = \\underset{\\left\\{p(\\tilde{\\mathbf{x}}|\\mathbf{x}): \\mathbb{E}_{p(\\mathbf{x},\\tilde{\\mathbf{x}})}\\left\\{d(x,\\tilde{x})\\right\\} \\leq D\\right\\}}{\\operatorname{min}} I(\\mathbf{X};\\tilde{\\mathbf{X}})\n",
        "\\end{equation}\n",
        "\n",
        "Lo anterior es equivalente a minimizar el funcional:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\mathcal{F}(p(\\tilde{\\mathbf{x}}|\\mathbf{x})) = \\underset{\\sum p(\\tilde{\\mathbf{x}}|\\mathbf{x}) = 1}{\\operatorname{min}} I(\\mathbf{X};\\tilde{\\mathbf{X}}) + \\beta \\mathbb{E}_{p(\\mathbf{x},\\tilde{\\mathbf{x}})}\\left\\{d(x,\\tilde{x})\\right\\}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLIo1nOxM-HO",
        "colab_type": "text"
      },
      "source": [
        "### 3.2.- Extensión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9LXjtANNEAN",
        "colab_type": "text"
      },
      "source": [
        "Introducimos ahora la variable en base a la cual definir la **información relevante** contenida en $\\mathbf{X}$, $\\mathbf{Y}$. Es en consecuencia esta variable la que define el valor de la medida de distorsión $d$.\n",
        "\n",
        "En forma similar a como interpretamos que $I(\\mathbf{X};\\tilde{\\mathbf{X}})$ corresponde a la información que $\\tilde{\\mathbf{X}}$ contiene de la variable $\\mathbf{X}$, $I(\\mathbf{Y};\\tilde{\\mathbf{X}})$ corresponde a la información contenida acerca de la variable para la cual queremos extraer la información relevante.\n",
        "\n",
        "Un supuesto importante de este problema es que la codificación $\\tilde{\\mathbf{X}}$ debe satisfacer la siguiente cadena de Markov:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\tilde{\\mathbf{X}} - \\mathbf{X} - \\mathbf{Y}\n",
        "\\end{equation}\n",
        "\n",
        "> **Nota**: Recordar que esta propiedad se traduce en la independencia condicional entre $\\tilde{\\mathbf{X}}$ y $\\mathbf{Y}$ dado $\\mathbf{X}$\n",
        "\n",
        "Esto es puesto que las estadísticas de $\\tilde{\\mathbf{X}}$ están sujetas únicamente a la variable de observación. Finalmente, el mapeo $p(\\tilde{\\mathbf{x}}|\\mathbf{x})$ óptimo se obtiene al resolver el problema de optimización \n",
        "\n",
        "\\begin{equation}\n",
        "  \\underset{\\sum p(\\tilde{\\mathbf{x}}|\\mathbf{x}) = 1}{\\operatorname{min}} I(\\mathbf{X};\\tilde{\\mathbf{X}}) - \\beta I(\\mathbf{Y};\\tilde{\\mathbf{X}})\n",
        "\\end{equation}\n",
        "\n",
        "Los sumandos de este problema de optimización son claramente objtetivos contrapuestos debido a la *data processing inequality* y la relación estadística entre $\\mathbf{X}$ y $\\tilde{\\mathbf{X}}$:\n",
        "\n",
        "Dadas las variables aleatorias $\\mathbf{X}$, $\\mathbf{Y}$ y $\\mathbf{Z}$ tales que se tiene la cadena de Markov $\\mathbf{Z} - \\mathbf{X} - \\mathbf{Y}$, se tendrá entonces que\n",
        "\\begin{equation}\n",
        "  I(\\mathbf{Y};\\mathbf{Z}) \\leq I(\\mathbf{Y};\\mathbf{X})\n",
        "\\end{equation}\n",
        "\n",
        "dándose la igualdad estricta cuando $I(\\mathbf{Y};\\mathbf{X}|\\mathbf{Z}) = 0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a8FDdtwWJWm",
        "colab_type": "text"
      },
      "source": [
        "El problema original de *rate-distortion theory* posee una solución cerrada para variables discretas y es posible encontrarla por medio del algoritmo de Blahut-Arimoto. Este resultado es extendible al problema del *Information Bottleneck* bajo la condición de Markovianidad.\n",
        "\n",
        "Extender este problema a variables aleatorias en un espacio contínuo no es trivial y es un problema aún abierto, en general. Una forma de abordar este problema es por medio de redes neuronales lo cual revisaremos en la **Tarea**, gracias a los contenidos de las secciones anteriores."
      ]
    }
  ]
}